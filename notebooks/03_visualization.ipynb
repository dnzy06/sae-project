{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311a136d-11ab-490c-b658-2bf9b3086c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sae_model import SparseAutoencoder\n",
    "import json\n",
    "import os\n",
    "\n",
    "models_dir = \"../models/\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", attn_implementation=\"eager\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff994ae-fdfc-487a-aa1e-7f25c2e397a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NUM = 7\n",
    "\n",
    "# Hook setup\n",
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "handle = model.transformer.h[LAYER_NUM].register_forward_hook(\n",
    "    get_activation(f'layer_{LAYER_NUM}')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3611923-2abd-422d-9edd-bf717d7e4636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (encoder): Linear(in_features=768, out_features=3840, bias=True)\n",
       "  (decoder): Linear(in_features=3840, out_features=768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(models_dir + \"sae_topk_final.pt\", map_location='cpu')\n",
    "\n",
    "# Extract config if saved, otherwise use defaults\n",
    "if 'config' in checkpoint:\n",
    "    config = checkpoint['config']\n",
    "    sae = SparseAutoencoder(\n",
    "        input_dim=config['input_dim'],\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        sparsity_coef=config['k'],  # k is the number of active features\n",
    "        normalize_eps=config.get('normalize_eps', 1e-6)\n",
    "    )\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "else:\n",
    "    # Fallback if config not saved\n",
    "    sae = SparseAutoencoder(input_dim=768, hidden_dim=3840, sparsity_coef=64)\n",
    "    state_dict = checkpoint if isinstance(checkpoint, dict) and 'encoder.weight' in checkpoint else checkpoint['model_state_dict']\n",
    "\n",
    "sae.load_state_dict(state_dict)\n",
    "sae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb55e430-c738-4c16-b26c-1a02d2709e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Testing visually to see if the sparse encoder actually works\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf0fe2c-bdf3-43f6-940f-6d038720a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "act = activations[f'layer_{LAYER_NUM}'][0]  # [seq_len, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb460c1a-8e80-4432-90b2-ce25014bc08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9cae61-0469-4686-93ef-c7c5f0e87bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
